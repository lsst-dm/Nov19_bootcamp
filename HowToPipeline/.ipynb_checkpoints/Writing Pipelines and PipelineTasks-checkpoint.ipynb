{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All the below expect testdata_ci_hsc and ci_hsc_gen3 to be setup\n",
    "\n",
    "### Start with a task\n",
    "PipelineTasks are Tasks that have extra information and methods to allow an executor to supply the data that it will need at the appropriate time. With this in mind, a good place to start and example is with a simple task like the one below. It's job is to do aperture naive aperture photometry on already identified sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.pipe.base as pipeBase\n",
    "import lsst.pex.config as pexConfig\n",
    "import lsst.afw.table as afwTable\n",
    "import lsst.afw.image as afwImage\n",
    "\n",
    "class ApertureTaskConfig(pexConfig.Config):\n",
    "    apRad = pexConfig.Field(doc=\"Radius of aperture\", dtype=int, default=4) \n",
    "\n",
    "class ApertureTask(pipeBase.Task):\n",
    "\n",
    "    ConfigClass = ApertureTaskConfig\n",
    "    _DefaultName = \"apertureTask\"\n",
    "    \n",
    "    def __init__(self, config: pexConfig.Config, *args, **kwargs):\n",
    "        super().__init__(*args, config=config, **kwargs)\n",
    "        self.apRad = self.config.apRad\n",
    "    \n",
    "        self.outputSchema = afwTable.SourceTable.makeMinimalSchema()\n",
    "        self.apKey = self.outputSchema.addField(\"apFlux\", type=np.float64, doc=\"Ap flux measured\")\n",
    "    \n",
    "        self.outputCatalog = afwTable.SourceCatalog(self.outputSchema)\n",
    "\n",
    "    def run(self, exposure: afwImage.Exposure, inputCatalog: afwTable.SourceCatalog) -> pipeBase.Struct:\n",
    "        # Get the dimensions of the exposure\n",
    "        dimensions = exposure.getDimensions()\n",
    "\n",
    "        # Get indexes for each pixel\n",
    "        indy, indx = np.indices((dimensions.getY(), dimensions.getX()))\n",
    "\n",
    "        # Loop over each record in the catalog\n",
    "        for source in inputCatalog:\n",
    "            # Create an aperture and measure the flux\n",
    "            center = source.getCentroid()\n",
    "            mask = ((indy - center.getY())**2 + (indx - center.getX())**2)**0.5 < self.apRad\n",
    "            flux = np.sum(exposure.image.array*mask)\n",
    "\n",
    "            # Add a record to the output catalog\n",
    "            tmpRecord = self.outputCatalog.addNew()\n",
    "            tmpRecord.set(self.apKey, flux)\n",
    "        \n",
    "        return self.outputCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertng to a Pipeline task\n",
    "\n",
    "The first thing a PipelineTask needs is a way for an executor to identify what dataset types the task will consume and produce. Additionally an executor needs to know what unit of work, or Quantum, the task will operate on. This information is defined inside a PipelineTaskConnections class, commonly refered to as a connections class. The following is an example of a connections class for the example ApertureTask that was defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApertureTaskConnections(pipeBase.PipelineTaskConnections,\n",
    "                              dimensions=(\"visit\", \"detector\", \"abstract_filter\", \"skymap\")):\n",
    "    exposure = pipeBase.connectionTypes.Input(doc=\"Input exposure to make measurements on\",\n",
    "                                              dimensions=(\"instrument\", \"visit\", \"detector\"),\n",
    "                                              storageClass=\"ExposureF\",\n",
    "                                              name=\"calexp\")\n",
    "    inputCatalog = pipeBase.connectionTypes.Input(doc=\"Input catalog with existing measurements\",\n",
    "                                                  dimensions=(\"instrument\", \"visit\", \"detector\",),\n",
    "                                                  storageClass=\"SourceCatalog\",\n",
    "                                                  name=\"src\") \n",
    "    outputCatalog = pipeBase.connectionTypes.Output(doc=\"Aperture measurements\",\n",
    "                                                    dimensions=(\"visit\", \"detector\", \"abstract_filter\",\n",
    "                                                                \"skymap\"),\n",
    "                                                    storageClass=\"SourceCatalog\",\n",
    "                                                    name=\"customAperture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A connections class is associated with a PipelineTask's Config class as seen below. This association serves not only to link the connections to a PipelineTask, but also provides a way to configure a connections dataset type name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApertureTaskConfig(pipeBase.PipelineTaskConfig,\n",
    "                         pipelineConnections=ApertureTaskConnections):\n",
    "    apRad = pexConfig.Field(doc=\"Radius of aperture\", dtype=float, default=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the ApertureTask itself is converted, which may be as simple as changing the base class for the Task. In this example the runQuantum method from PipelineTask is also overloaded to demonstrate how it works, and how it can be used to alter arguments before run is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we modify the task to make it a command line task\n",
    "\n",
    "class ApertureTask(pipeBase.PipelineTask):\n",
    "\n",
    "    ConfigClass = ApertureTaskConfig\n",
    "    _DefaultName = \"apertureTask\"\n",
    "\n",
    "    def __init__(self, config: pipeBase.PipelineTaskConfig, *args, **kwargs):\n",
    "        super().__init__(*args, config=config, **kwargs)\n",
    "        self.apRad = self.config.apRad\n",
    "\n",
    "        self.outputSchema = afwTable.SourceTable.makeMinimalSchema()\n",
    "        self.apKey = self.outputSchema.addField(\"apFlux\", type=np.float64, doc=\"Ap flux measured\")\n",
    "\n",
    "        self.outputCatalog = afwTable.SourceCatalog(self.outputSchema)\n",
    "\n",
    "    def run(self, exposure: afwImage.Exposure, inputCatalog: afwTable.SourceCatalog, msg: str) -> pipeBase.Struct:\n",
    "        self.log.info(f\"Running aperture phot {msg}\")\n",
    "        # Get the dimensions of the exposure\n",
    "        dimensions = exposure.getDimensions()\n",
    "\n",
    "        # Get indexes for each pixel\n",
    "        indy, indx = np.indices((dimensions.getY(), dimensions.getX()))\n",
    "\n",
    "        # Loop over each record in the catalog\n",
    "        for i, source in enumerate(inputCatalog):\n",
    "            if i%100 == 0:\n",
    "                self.log.info(f\"Processing record {i}\")\n",
    "            # Create an aperture and measure the flux\n",
    "            center = source.getCentroid()\n",
    "            mask = ((indy - center.getY())**2 + (indx - center.getX())**2)**0.5 < self.apRad\n",
    "            flux = np.sum(exposure.image.array*mask)\n",
    "\n",
    "            # Add a record to the output catalog\n",
    "            tmpRecord = self.outputCatalog.addNew()\n",
    "            tmpRecord.set(self.apKey, flux)\n",
    "\n",
    "        return pipeBase.Struct(outputCatalog=self.outputCatalog)\n",
    "    \n",
    "    def runQuantum(self, butlerQC: pipeBase.ButlerQuantumContext,\n",
    "                   inputRefs: pipeBase.InputQuantizedConnection,\n",
    "                   outputRefs: pipeBase.OutputQuantizedConnection):\n",
    "        inputs = butlerQC.get(inputRefs)\n",
    "        # Add an extra argument that is to be passed to run, this is not\n",
    "        # part of the base class runQuantum\n",
    "        inputs['msg'] = str(butlerQC.quantum.dataId)\n",
    "        outputs = self.run(**inputs)\n",
    "        butlerQC.put(outputs, outputRefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the names of the attributes of the connection class which are inputs match the arguments to the run method. The attribute name that is an output type matches the attribute name in the `Struct` that is returned by the run method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctrl.mpexec.cmdLineFwk INFO: QuantumGraph contains 1 quanta for 1 tasks\n",
      "apertureTask INFO: Running aperture phot {'instrument': 'HSC', 'skymap': 'discrete/ci_hsc', 'detector': 22, 'visit': 903334}\n",
      "apertureTask INFO: Processing record 0\n",
      "apertureTask INFO: Processing record 100\n",
      "apertureTask INFO: Processing record 200\n",
      "apertureTask INFO: Processing record 300\n",
      "apertureTask INFO: Processing record 400\n",
      "apertureTask INFO: Processing record 500\n",
      "apertureTask INFO: Processing record 600\n",
      "apertureTask INFO: Processing record 700\n",
      "apertureTask INFO: Processing record 800\n"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH=$PYTHONPATH:$(pwd) pipetask run -j 1 -b \"$CI_HSC_GEN3_DIR\"/DATA/butler.yaml -i shared/ci_hsc_output -o aptest6 --register-dataset-types -t WritingPipelineTasks.ApertureTask -d \"detector = 22 AND visit = 903334 AND abstract_filter = 'r'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And so much more\n",
    "There is a lot more this demo does not cover, but an indepth demo that exapnds on what was laied out here will soon be merged into the documentation of pipe_base. This includes things like\n",
    "\n",
    "* Arguments to init\n",
    "* Optional datasets\n",
    "* Shared templates for dataset type names\n",
    "* Prerequisite inputs\n",
    "* Controlling the parallelization axis\n",
    "* Deferred loading of datasets\n",
    "* Altering connections through configuration\n",
    "* Validating quanta prior to execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a pipeline document\n",
    "Now that the `ApertureTask` is a `PipelineTask` it can be put into a pipeline. As it is a measurement on a single detector, it makes sense to extend the single detector processing with this task. Below is a pipeline that does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description: \"A demo for DM BootCamp 2019\"\r\n",
      "\r\n",
      "# This pipeline should run against HSC data, this loads relevant overrides\r\n",
      "instrument: lsst.obs.subaru.gen3.hsc.instrument.HyperSuprimeCam\r\n",
      "\r\n",
      "# Extend the default ProcessCcd, but exclude isr and characterizeImage tasks\r\n",
      "# for the sake of time\r\n",
      "inherits:\r\n",
      "  location: $PIPE_TASKS_DIR/pipelines/ProcessCcd.yaml\r\n",
      "  exclude:\r\n",
      "    - isr\r\n",
      "    - charImage\r\n",
      "\r\n",
      "# Add in the Task that was just created\r\n",
      "tasks:\r\n",
      "  example:\r\n",
      "    class: WritingPipelineTasks.ApertureTask\r\n",
      "    config:\r\n",
      "      # Set the radius for the aperture\r\n",
      "      apRad: 4.5\r\n",
      "      # change the name of the output dataset type\r\n",
      "      connections.outputCatalog: extraAperture\r\n",
      "\r\n",
      "contracts:\r\n",
      "  # verify that the aperture used in this pipeine is also used in the default\r\n",
      "  # circular aperture\r\n",
      "  - example.apRad in calibrate.measurement.plugins[\"base_CircularApertureFlux\"].radii\r\n"
     ]
    }
   ],
   "source": [
    "!cat DemoPipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using python it is possible to see what the expanded pipeline will look like before it is executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description: A demo for DM BootCamp 2019\n",
      "instrument: lsst.obs.subaru.gen3.hsc.instrument.HyperSuprimeCam\n",
      "tasks:\n",
      "  calibrate:\n",
      "    class: lsst.pipe.tasks.calibrate.CalibrateTask\n",
      "  example:\n",
      "    class: WritingPipelineTasks.ApertureTask\n",
      "    config:\n",
      "    - apRad: 4.5\n",
      "      connections.outputCatalog: extraAperture\n",
      "contracts:\n",
      "- contract: example.apRad in calibrate.measurement.plugins[\"base_CircularApertureFlux\"].radii\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pipeBase.Pipeline.fromFile(\"DemoPipeline.yaml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipeline\n",
    "Pipelines are run very similar to regular tasks, specifying a pipeline instead of, or in addition to, tasks defined on the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctrl.mpexec.cmdLineFwk INFO: QuantumGraph contains 2 quanta for 2 tasks\n",
      "calibrate.detection INFO: Detected 3974 positive peaks in 757 footprints and 8085 negative peaks in 169 footprints to 5 sigma\n",
      "calibrate.detection INFO: Resubtracting the background after object detection\n",
      "calibrate.deblend INFO: Deblending 757 sources\n",
      "calibrate.deblend WARN: Parent 775958091962253313: skipping masked footprint (area: 293)\n",
      "calibrate.deblend WARN: Parent 775958091962253320: skipping masked footprint (area: 619)\n",
      "calibrate.deblend WARN: Parent 775958091962253325: skipping masked footprint (area: 2489)\n",
      "calibrate.deblend WARN: Parent 775958091962253329: skipping masked footprint (area: 668)\n",
      "calibrate.deblend WARN: Parent 775958091962253338: skipping masked footprint (area: 503)\n",
      "calibrate.deblend WARN: Parent 775958091962253340: skipping masked footprint (area: 299)\n",
      "calibrate.deblend WARN: Parent 775958091962253341: skipping masked footprint (area: 331)\n",
      "calibrate.deblend WARN: Parent 775958091962253343: skipping masked footprint (area: 993)\n",
      "calibrate.deblend WARN: Parent 775958091962253353: skipping masked footprint (area: 695)\n",
      "calibrate.deblend WARN: Parent 775958091962253354: skipping masked footprint (area: 431)\n",
      "calibrate.deblend WARN: Parent 775958091962253356: skipping masked footprint (area: 912)\n",
      "calibrate.deblend WARN: Parent 775958091962253374: skipping masked footprint (area: 331)\n",
      "calibrate.deblend WARN: Parent 775958091962253381: skipping masked footprint (area: 316)\n",
      "calibrate.deblend WARN: Parent 775958091962253391: skipping masked footprint (area: 579)\n",
      "calibrate.deblend WARN: Parent 775958091962253394: skipping masked footprint (area: 447)\n",
      "calibrate.deblend WARN: Parent 775958091962253395: skipping masked footprint (area: 551)\n",
      "calibrate.deblend WARN: Parent 775958091962253409: skipping masked footprint (area: 432)\n",
      "calibrate.deblend WARN: Parent 775958091962253433: skipping masked footprint (area: 789)\n",
      "calibrate.deblend WARN: Parent 775958091962253438: skipping masked footprint (area: 1295)\n",
      "calibrate.deblend WARN: Parent 775958091962253445: skipping large footprint (area: 713081)\n",
      "calibrate.deblend WARN: Parent 775958091962253446: skipping masked footprint (area: 2413)\n",
      "calibrate.deblend WARN: Parent 775958091962253461: skipping masked footprint (area: 722)\n",
      "calibrate.deblend WARN: Parent 775958091962253462: skipping masked footprint (area: 1025)\n",
      "calibrate.deblend WARN: Parent 775958091962253465: skipping masked footprint (area: 1843)\n",
      "calibrate.deblend WARN: Parent 775958091962253470: skipping masked footprint (area: 1044)\n",
      "calibrate.deblend WARN: Parent 775958091962253480: skipping masked footprint (area: 1356)\n",
      "calibrate.deblend WARN: Parent 775958091962253579: skipping masked footprint (area: 1268)\n",
      "calibrate.deblend WARN: Parent 775958091962253617: skipping large footprint (area: 84089)\n",
      "calibrate.deblend WARN: Parent 775958091962253709: skipping large footprint (area: 10908)\n",
      "calibrate.deblend WARN: Parent 775958091962253761: skipping large footprint (area: 36860)\n",
      "calibrate.deblend WARN: Parent 775958091962254068: skipping large footprint (area: 11305)\n",
      "calibrate.deblend INFO: Deblended: of 757 sources, 61 were deblended, creating 130 children, total 887 sources\n",
      "calibrate.measurement INFO: Measuring 887 sources (757 parents, 130 children) \n",
      "calibrate.applyApCorr INFO: Applying aperture corrections to 3 instFlux fields\n",
      "calibrate INFO: Copying flags from icSourceCat to sourceCat for 161 sources\n",
      "calibrate.astrometry INFO: Purged 753 sources, leaving 134 good sources\n",
      "calibrate INFO: Loading reference objects from region bounded by [-0.005949410255678461, -0.004108399416702666], [5.599823835638792, 5.603106751615399] lat lon\n",
      "calibrate INFO: Loaded 1010 reference objects\n",
      "calibrate WARN: Catalog pm_ra field is not an Angle; not applying proper motion\n",
      "calibrate WARN: Found version 0 reference catalog with old style units in schema.\n",
      "calibrate WARN: run `meas_algorithms/bin/convert_refcat_to_nJy.py` to convert fluxes to nJy.\n",
      "calibrate WARN: See RFC-575 for more details.\n",
      "calibrate INFO: Converted refcat flux fields to nJy (name, units): (g_flux, ''); (r_flux, ''); (i_flux, ''); (z_flux, ''); (y_flux, ''); (i_fluxSigma, ''); (y_fluxSigma, ''); (r_fluxSigma, ''); (z_fluxSigma, ''); (g_fluxSigma, '')\n",
      "calibrate.astrometry.referenceSelector INFO: Selected 1010/1010 references\n",
      "calibrate.astrometry.matcher INFO: Matched 133 sources\n",
      "calibrate.astrometry.matcher INFO: Matched 133 sources\n",
      "calibrate.astrometry.matcher INFO: Matched 133 sources\n",
      "calibrate.astrometry INFO: Matched and fit WCS in 3 iterations; found 133 matches with scatter = 0.017 +- 0.013 arcsec\n",
      "calibrate.photoCal.match.sourceSelection INFO: Selected 268/887 sources\n",
      "calibrate INFO: Loading reference objects from region bounded by [-0.006814670074476605, -0.0033142431743507653], [5.5997185505511275, 5.603219052342515] lat lon\n",
      "calibrate INFO: Loaded 1988 reference objects\n",
      "calibrate WARN: Found version 0 reference catalog with old style units in schema.\n",
      "calibrate WARN: run `meas_algorithms/bin/convert_refcat_to_nJy.py` to convert fluxes to nJy.\n",
      "calibrate WARN: See RFC-575 for more details.\n",
      "calibrate INFO: Converted refcat flux fields to nJy (name, units): (g_flux, ''); (r_flux, ''); (i_flux, ''); (z_flux, ''); (y_flux, ''); (i_fluxSigma, ''); (y_fluxSigma, ''); (r_fluxSigma, ''); (z_fluxSigma, ''); (g_fluxSigma, '')\n",
      "calibrate.photoCal.match.referenceSelection INFO: Selected 344/1988 references\n",
      "calibrate.photoCal.match INFO: Matched 73 from 268/887 input and 344/1988 reference sources\n",
      "calibrate.photoCal.reserve INFO: Reserved 0/73 sources\n",
      "calibrate.photoCal INFO: Applying color terms for filterName='HSC-R', config.photoCatName=ps1_pv3_3pi_20170110 because config.applyColorTerms is True\n",
      "calibrate.photoCal INFO: Magnitude zero point: 30.584351 +/- 0.000214 from 64 stars\n",
      "calibrate INFO: Photometric zero-point: 30.584351\n",
      "apertureTask INFO: Running aperture phot {'instrument': 'HSC', 'skymap': 'discrete/ci_hsc', 'detector': 22, 'visit': 903334}\n",
      "apertureTask INFO: Processing record 0\n",
      "apertureTask INFO: Processing record 100\n",
      "apertureTask INFO: Processing record 200\n",
      "apertureTask INFO: Processing record 300\n",
      "apertureTask INFO: Processing record 400\n",
      "apertureTask INFO: Processing record 500\n",
      "apertureTask INFO: Processing record 600\n",
      "apertureTask INFO: Processing record 700\n",
      "apertureTask INFO: Processing record 800\n"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH=$PYTHONPATH:$(pwd) pipetask run -j 1 -b \"$CI_HSC_GEN3_DIR\"/DATA/butler.yaml -i shared/ci_hsc_output -o aptest-7 --register-dataset-types -p DemoPipeline.yaml -d \"detector = 22 AND visit = 903334 AND abstract_filter = 'r'\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read back in the dataset to verify the execution was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414.15576171875\n"
     ]
    }
   ],
   "source": [
    "import lsst.daf.butler as dafButler\n",
    "from lsst.utils import getPackageDir\n",
    "import os\n",
    "\n",
    "# Define path to butler\n",
    "butler_loc = os.path.join(getPackageDir(\"ci_hsc_gen3\"), \"DATA/butler.yaml\")\n",
    "\n",
    "# Create a butler\n",
    "butler = dafButler.Butler(butler_loc, collection=\"aptest-7\")\n",
    "\n",
    "# Fetch the dataset\n",
    "fluxes = butler.get(\"extraAperture\", {\"detector\": 22, \"visit\":903334, \"instrument\":\"HSC\", \"skymap\":\"discrete/ci_hsc\"})\n",
    "\n",
    "# Print a flux\n",
    "print(fluxes[100][\"apFlux\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
